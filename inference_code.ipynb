{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install gdown\n","import gdown\n","url = \"https://drive.google.com/uc?=dmfkadfkadsnkfdn/dfdae2322\"\n","output_file = \"model.sav\"\n","gdown.download(url, output_file, quiet=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generator = tf.keras.models.load_model('generator')\n","discriminator = tf.keras.models.load_model('discriminator')\n","\n","def generate_images_test(model, test_input, plot=False):\n","    prediction = model(test_input, training=True)\n","    \n","    display_list = [test_input[0], prediction[0]]\n","    title = ['Input Image',  'Predicted Image']\n","\n","    if plot==True:\n","        plt.figure(figsize=(15, 15))\n","        for i in range(2):\n","            plt.subplot(1, 3, i+1)\n","            plt.title(title[i])\n","            # Getting the pixel values in the [0, 1] range to plot.\n","            plt.imshow(display_list[i] * 0.5 + 0.5)\n","            plt.axis('off')\n","        plt.show()\n","    return prediction[0]\n","\n","content_dir = \"Dataset/Testing_Data/\"\n","mask_dir = \"/kaggle/working/mask_files\"\n","gen_dir = \"/kaggle/working/gen_files\"\n","sub_dir = \"submission\"\n","metadata = pd.read_csv(content_dir + \"masked_info.csv\")\n","f = open(\"Final_csv_file.csv\",\"w\")\n","f.write(\"filename_box_pixel,Value\\n\")\n","vals_dict = {\n","    'filename_box_pixel' : [],\n","    'Value' : []\n","}\n","print(metadata.shape[0])\n","model = tf.keras.models.load_model('model')\n","for idx in range(metadata.shape[0]):\n","    _, filename, mask1_y, mask1_x, mask2_y, mask2_x = metadata.iloc[idx,:].tolist()\n","    cords_box1 = [(row, col) for row in range(mask1_y,  mask1_y + 75) for col in range(mask1_x,  mask1_x + 75)]\n","    cords_box2 = [(row, col) for row in range(mask2_y,  mask2_y + 75) for col in range(mask2_x,  mask2_x + 75)]\n","    box_cords = {'box1' : cords_box1, 'box2' : cords_box2}\n","    img_path = 'Dataset/Testing_Data/'+filename  # path to test image\n","    img = cv2.imread(img_path)  # load image using OpenCV\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # convert to RGB format\n","    img = cv2.resize(img, (256, 256))  # resize to match model input shape\n","    img = img / 255.0  # normalize pixel values to range [0, 1]\n","    img = np.expand_dims(img, axis=0)  # add batch dimension\n","    inpainted_img = model.predict([img,img])\n","    test_results = inpainted_img[0]  # remove batch dimension\n","    for box, all_cords in box_cords.items():\n","        for px_cords in all_cords:\n","            b = test_results[px_cords[0]][px_cords[1]][0]\n","            g = test_results[px_cords[0]][px_cords[1]][1]\n","            r = test_results[px_cords[0]][px_cords[1]][2]\n","            px_name_b = filename + \"_\" + box + \"_\" + str(px_cords[0]) + \"_\" + str(px_cords[1]) + \"_0\"\n","            px_name_g = filename + \"_\" + box + \"_\" + str(px_cords[0]) + \"_\" + str(px_cords[1]) + \"_1\"\n","            px_name_r = filename + \"_\" + box + \"_\" + str(px_cords[0]) + \"_\" + str(px_cords[1]) + \"_2\"\n","            f.write(px_name_b+\",\"+str(b)+\"\\n\")\n","            f.write(px_name_g+\",\"+str(g)+\"\\n\")\n","            f.write(px_name_r+\",\"+str(r)+\"\\n\")\n","    if idx % 5 == 0:\n","        print(idx)\n","f.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
